{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:31:33.031102Z",
     "start_time": "2024-03-08T20:31:00.273243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing images for person 0...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 78\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# Set the desired resolution (width, height)\u001B[39;00m\n\u001B[0;32m     76\u001B[0m resolution \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1280\u001B[39m, \u001B[38;5;241m720\u001B[39m)  \u001B[38;5;66;03m# Change this to your desired resolution\u001B[39;00m\n\u001B[1;32m---> 78\u001B[0m \u001B[43mcapture_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_images_per_person\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolution\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[4], line 61\u001B[0m, in \u001B[0;36mcapture_images\u001B[1;34m(output_folder, num_images_per_person, resolution)\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[38;5;66;03m# Display captured image (optional)\u001B[39;00m\n\u001B[0;32m     60\u001B[0m         img\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m---> 61\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Display each image for 1 second\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# Release video capture\u001B[39;00m\n\u001B[0;32m     64\u001B[0m cap\u001B[38;5;241m.\u001B[39mrelease()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to capture images and save them to individual folders\n",
    "def capture_images(output_folder, num_images_per_person, resolution=(640, 480)):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(\"Directory created successfully!\")\n",
    "\n",
    "    # TensorFlow model for processing images (example)\n",
    "    model = tf.keras.applications.MobileNetV2(weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "    # OpenCV video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Set resolution\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, resolution[0])\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, resolution[1])\n",
    "\n",
    "    # Loop to capture images\n",
    "    for person_id in range(num_persons):\n",
    "        person_folder = os.path.join(output_folder)\n",
    "        if not os.path.exists(person_folder):\n",
    "            os.makedirs(person_folder)\n",
    "\n",
    "        print(f\"Capturing images for person {person_id}...\")\n",
    "\n",
    "        # Loop to capture multiple images per person\n",
    "        for img_count in range(num_images_per_person):\n",
    "            # Capture frame using OpenCV\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Convert frame to Pillow image\n",
    "            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "            # Resize image to match the input shape of the model\n",
    "            img = img.resize((224, 224))\n",
    "\n",
    "            # Convert image to numpy array and preprocess for the model\n",
    "            img_array = np.array(img)\n",
    "            img_array = img_array / 255.0  # Normalize pixel values\n",
    "            img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "            # Make predictions using the model (example)\n",
    "            predictions = model.predict(img_array)\n",
    "\n",
    "            # Example: Get top 3 predicted classes\n",
    "            top_classes = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "            # Save the image\n",
    "            img.save(os.path.join(person_folder, f'img_{img_count}.jpg'))\n",
    "\n",
    "            # Display captured image (optional)\n",
    "            img.show()\n",
    "            time.sleep(1)  # Display each image for 1 second\n",
    "\n",
    "    # Release video capture\n",
    "    cap.release()\n",
    "\n",
    "    print(\"Image capture complete!\")\n",
    "\n",
    "# Example usage:\n",
    "folder_name = input(\"Enter the roll no : \")\n",
    "output_folder = f'dataset/Images/train/{folder_name}'\n",
    "\n",
    "num_persons = 1  # Change this according to the number of persons you want to capture\n",
    "num_images_per_person = 20  # Change this according to the number of images you want to capture per person\n",
    "\n",
    "# Set the desired resolution (width, height)\n",
    "resolution = (1280, 720)  # Change this to your desired resolution\n",
    "\n",
    "capture_images(output_folder, num_images_per_person, resolution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
